{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM vs Traditional NLP: Character Analysis Comparison\n",
    "\n",
    "This notebook compares traditional NLTK-based character extraction with modern LLM-based approaches.\n",
    "\n",
    "## Key Questions Addressed:\n",
    "1. Can LLMs do the general NLP work for character analysis?\n",
    "2. What are the advantages and limitations of each approach?\n",
    "3. When should you use which approach?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (uncomment if needed)\n",
    "# !pip install nltk pandas\n",
    "# !pip install openai  # For LLM approach\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Text\n",
    "\n",
    "We'll use a sample excerpt that demonstrates the challenges of character extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = \"\"\"\n",
    "PART I - THE PSYCHOHISTORIANS\n",
    "\n",
    "Hari Seldon stood before the Galactic Emperor in the grand throne room of Trantor. \n",
    "The Emperor, whose full name was Cleon I, leaned forward with interest. \n",
    "\"Well, Seldon,\" he said, \"explain this psychohistory of yours.\"\n",
    "\n",
    "Gaal Dornick, Hari's young apprentice, watched from the sidelines. He had traveled \n",
    "from his home planet to study under the great Hari Seldon. The Foundation would \n",
    "depend on people like Gaal.\n",
    "\n",
    "\"Your Highness,\" Hari began, \"the mathematics are clear. The Galactic Empire will fall.\"\n",
    "\n",
    "The Emperor's advisor, Lord Dorwin, gasped audibly. \"Master Seldon speaks treason!\" \n",
    "he cried.\n",
    "\n",
    "But Cleon merely smiled. \"Yes, yes, Lord Dorwin. Let the man speak.\"\n",
    "\n",
    "Gaal felt his heart pounding. Would the Emperor believe in Seldon's vision? Would \n",
    "they be allowed to establish the Foundation on Terminus, at the edge of the Galaxy?\n",
    "\"\"\"\n",
    "\n",
    "print(f\"Sample text length: {len(sample_text)} characters\")\n",
    "print(f\"Sample text:\\n{sample_text[:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 1: Traditional NLP (NLTK)\n",
    "\n",
    "This is the approach used in the original Foundation.ipynb notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download required NLTK data\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('averaged_perceptron_tagger', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "\n",
    "print(\"NLTK resources downloaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_characters_traditional(text, min_frequency=1):\n",
    "    \"\"\"\n",
    "    Extract character names using traditional NLTK-based NLP.\n",
    "    This mirrors the approach in Foundation.ipynb.\n",
    "    \"\"\"\n",
    "    # Tokenize into sentences and words\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    tokenized_sentences = [nltk.word_tokenize(sentence) for sentence in sentences]\n",
    "    \n",
    "    # POS tagging\n",
    "    tagged_sentences = [nltk.pos_tag(sentence) for sentence in tokenized_sentences]\n",
    "    \n",
    "    # Extract proper nouns (NNP tags)\n",
    "    proper_nouns = []\n",
    "    for sent in tagged_sentences:\n",
    "        for word, tag in sent:\n",
    "            if tag == 'NNP' and word.isalpha() and len(word) > 1:\n",
    "                proper_nouns.append(word)\n",
    "    \n",
    "    # Count frequencies\n",
    "    word_freq = defaultdict(int)\n",
    "    for word in proper_nouns:\n",
    "        word_freq[word] += 1\n",
    "    \n",
    "    # Filter by minimum frequency\n",
    "    characters = {word: count for word, count in word_freq.items() \n",
    "                  if count >= min_frequency}\n",
    "    \n",
    "    return characters\n",
    "\n",
    "# Run traditional extraction\n",
    "traditional_chars = extract_characters_traditional(sample_text, min_frequency=1)\n",
    "traditional_df = pd.DataFrame(list(traditional_chars.items()), \n",
    "                               columns=['Character', 'Count']).sort_values('Count', ascending=False)\n",
    "\n",
    "print(\"\\n=== Traditional NLP Results ===\")\n",
    "print(traditional_df.to_string(index=False))\n",
    "print(f\"\\nTotal entities found: {len(traditional_chars)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of Traditional Approach Results\n",
    "\n",
    "**Issues with Traditional NLP:**\n",
    "1. **Splits names**: \"Hari\" and \"Seldon\" are counted separately\n",
    "2. **Includes locations**: \"Trantor\", \"Terminus\", \"Galaxy\" identified as characters\n",
    "3. **Includes titles**: \"Master\", \"Lord\", \"Emperor\" treated as character names\n",
    "4. **Misses aliases**: Doesn't connect \"Cleon\" with \"Emperor\"\n",
    "5. **False positives**: \"Foundation\", \"Empire\" counted as names\n",
    "6. **No context**: Can't distinguish \"Well\" (word) from actual names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 2: LLM-Based Analysis\n",
    "\n",
    "Demonstrates what an LLM can do better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulated LLM response (what you would get from GPT-4, Claude, etc.)\n",
    "# In practice, you would call the actual LLM API\n",
    "\n",
    "llm_response_json = \"\"\"[\n",
    "  {\n",
    "    \"name\": \"Hari Seldon\",\n",
    "    \"aliases\": [\"Hari\", \"Seldon\", \"Master Seldon\"],\n",
    "    \"confidence\": 0.99,\n",
    "    \"role\": \"protagonist\",\n",
    "    \"type\": \"character\",\n",
    "    \"first_mention\": \"stood before the Galactic Emperor\",\n",
    "    \"description\": \"Mathematician, creator of psychohistory, main character\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Cleon I\",\n",
    "    \"aliases\": [\"Emperor\", \"Cleon\", \"Your Highness\", \"the Emperor\"],\n",
    "    \"confidence\": 0.98,\n",
    "    \"role\": \"supporting\",\n",
    "    \"type\": \"character\",\n",
    "    \"first_mention\": \"Galactic Emperor in the grand throne room\",\n",
    "    \"description\": \"Current Galactic Emperor, shows interest in psychohistory\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Gaal Dornick\",\n",
    "    \"aliases\": [\"Gaal\", \"Dornick\"],\n",
    "    \"confidence\": 0.97,\n",
    "    \"role\": \"supporting\",\n",
    "    \"type\": \"character\",\n",
    "    \"first_mention\": \"Hari's young apprentice\",\n",
    "    \"description\": \"Young apprentice to Hari Seldon, from off-world\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Lord Dorwin\",\n",
    "    \"aliases\": [\"Dorwin\", \"Lord Dorwin\"],\n",
    "    \"confidence\": 0.95,\n",
    "    \"role\": \"minor\",\n",
    "    \"type\": \"character\",\n",
    "    \"first_mention\": \"The Emperor's advisor\",\n",
    "    \"description\": \"Emperor's advisor, reacts strongly to Seldon's predictions\"\n",
    "  }\n",
    "]\"\"\"\n",
    "\n",
    "llm_characters = json.loads(llm_response_json)\n",
    "llm_df = pd.DataFrame(llm_characters)[['name', 'role', 'confidence', 'aliases']]\n",
    "\n",
    "print(\"\\n=== LLM-Based Results ===\")\n",
    "print(llm_df.to_string(index=False))\n",
    "print(f\"\\nTotal characters found: {len(llm_characters)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of LLM Approach Results\n",
    "\n",
    "**Advantages of LLM:**\n",
    "1. ✅ **Merged names**: \"Hari Seldon\" recognized as single character with aliases\n",
    "2. ✅ **Filtered locations**: No false positives for Trantor, Terminus, Galaxy\n",
    "3. ✅ **Understood context**: Recognized \"Emperor\" and \"Cleon I\" as same person\n",
    "4. ✅ **Proper classification**: Distinguished titles from character names\n",
    "5. ✅ **Added semantics**: Provided roles (protagonist, supporting, minor)\n",
    "6. ✅ **Confidence scores**: Indicated certainty of identification\n",
    "7. ✅ **Relationship info**: Identified mentor-apprentice relationship"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Side-by-Side Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== COMPARISON ===\")\n",
    "print(f\"\\nTraditional NLP found {len(traditional_chars)} entities:\")\n",
    "print(\", \".join(sorted(traditional_chars.keys())))\n",
    "\n",
    "llm_names = [char['name'] for char in llm_characters]\n",
    "print(f\"\\nLLM found {len(llm_names)} actual characters:\")\n",
    "print(\", \".join(llm_names))\n",
    "\n",
    "# Analyze false positives in traditional approach\n",
    "traditional_names_set = set(traditional_chars.keys())\n",
    "actual_character_words = set()\n",
    "for char in llm_characters:\n",
    "    actual_character_words.update(char['aliases'])\n",
    "    \n",
    "false_positives = traditional_names_set - actual_character_words\n",
    "\n",
    "print(f\"\\nFalse Positives in Traditional Approach ({len(false_positives)}):\")\n",
    "print(\", \".join(sorted(false_positives)))\n",
    "print(\"\\nThese are locations, organizations, or titles incorrectly identified as characters.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantitative Comparison Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_data = {\n",
    "    'Metric': [\n",
    "        'Entities Extracted',\n",
    "        'True Characters',\n",
    "        'False Positives',\n",
    "        'Aliases Merged',\n",
    "        'Context Understanding',\n",
    "        'Processing Time',\n",
    "        'Requires Manual Curation',\n",
    "        'Cost'\n",
    "    ],\n",
    "    'Traditional NLP': [\n",
    "        len(traditional_chars),\n",
    "        '~4-5 (needs manual review)',\n",
    "        len(false_positives),\n",
    "        'No',\n",
    "        'No',\n",
    "        '<1 second',\n",
    "        'Yes (significant)',\n",
    "        'Free'\n",
    "    ],\n",
    "    'LLM Approach': [\n",
    "        len(llm_characters),\n",
    "        '4 (accurate)',\n",
    "        '0',\n",
    "        'Yes (automatic)',\n",
    "        'Yes (excellent)',\n",
    "        '~2-5 seconds',\n",
    "        'No (minimal)',\n",
    "        '~$0.001-0.01 per request'\n",
    "    ]\n",
    "}\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "print(\"\\n=== DETAILED COMPARISON ===\")\n",
    "print(comparison_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relationship Analysis: What LLMs Add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulated LLM relationship analysis\n",
    "llm_relationships = {\n",
    "    \"relationships\": [\n",
    "        {\n",
    "            \"character1\": \"Hari Seldon\",\n",
    "            \"character2\": \"Gaal Dornick\",\n",
    "            \"type\": \"mentor-student\",\n",
    "            \"strength\": 8,\n",
    "            \"description\": \"Master-apprentice relationship, Gaal studies under Hari\",\n",
    "            \"sentiment\": \"positive\"\n",
    "        },\n",
    "        {\n",
    "            \"character1\": \"Hari Seldon\",\n",
    "            \"character2\": \"Cleon I\",\n",
    "            \"type\": \"formal/political\",\n",
    "            \"strength\": 6,\n",
    "            \"description\": \"Subject presenting to emperor, tense but respectful\",\n",
    "            \"sentiment\": \"neutral\"\n",
    "        },\n",
    "        {\n",
    "            \"character1\": \"Cleon I\",\n",
    "            \"character2\": \"Lord Dorwin\",\n",
    "            \"type\": \"advisor-ruler\",\n",
    "            \"strength\": 7,\n",
    "            \"description\": \"Emperor's advisor, loyal but cautious\",\n",
    "            \"sentiment\": \"positive\"\n",
    "        },\n",
    "        {\n",
    "            \"character1\": \"Lord Dorwin\",\n",
    "            \"character2\": \"Hari Seldon\",\n",
    "            \"type\": \"adversarial\",\n",
    "            \"strength\": 5,\n",
    "            \"description\": \"Advisor views Seldon's words as treasonous\",\n",
    "            \"sentiment\": \"negative\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "relationship_df = pd.DataFrame(llm_relationships['relationships'])\n",
    "print(\"\\n=== LLM RELATIONSHIP ANALYSIS ===\")\n",
    "print(\"Traditional NLP: Only provides co-occurrence counts\")\n",
    "print(\"LLM Analysis: Provides rich contextual relationships\\n\")\n",
    "print(relationship_df[['character1', 'character2', 'type', 'strength', 'sentiment']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practical Recommendations\n",
    "\n",
    "### When to Use Traditional NLP:\n",
    "- ✅ Processing very large corpora (thousands of books)\n",
    "- ✅ Need deterministic, reproducible results\n",
    "- ✅ Have a curated character list already\n",
    "- ✅ Only need quantitative metrics (counts, co-occurrence)\n",
    "- ✅ Zero budget or offline requirements\n",
    "- ✅ Real-time processing needs\n",
    "\n",
    "### When to Use LLMs:\n",
    "- ✅ Analyzing 1-100 books\n",
    "- ✅ Need high-quality character extraction\n",
    "- ✅ Want relationship quality analysis\n",
    "- ✅ Need character trait extraction\n",
    "- ✅ Can tolerate API costs ($0.50-5 per book)\n",
    "- ✅ Complex character aliases and variations\n",
    "\n",
    "### Hybrid Approach (Recommended):\n",
    "1. **Use LLM once** to create curated character list\n",
    "2. **Use Traditional NLP** for ongoing quantitative analysis\n",
    "3. **Use LLM** for deep dives on specific character relationships\n",
    "\n",
    "**Best of both worlds**: Accuracy + Speed + Cost-effectiveness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "**Can LLMs do the general NLP work for character analysis?**\n",
    "\n",
    "**YES**, and they do it **significantly better** for:\n",
    "- ✅ Character identification and disambiguation\n",
    "- ✅ Alias merging and name variations\n",
    "- ✅ Filtering false positives (locations, titles)\n",
    "- ✅ Understanding relationships and context\n",
    "- ✅ Providing semantic analysis\n",
    "\n",
    "**However**, traditional NLP remains valuable for:\n",
    "- ✅ Large-scale processing\n",
    "- ✅ Cost-sensitive applications\n",
    "- ✅ Deterministic results\n",
    "- ✅ Offline processing\n",
    "\n",
    "**The future is hybrid**: Use LLMs for curation and deep analysis, traditional NLP for bulk processing."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
